
[toc]

![](https://img-blog.csdnimg.cn/6a8575676e1e40489bb004f06c8b425a.png)

本文主要梳理总结学习清华大学青年AI自强项目中的核心知识内容，各位读者可以根据需要按图索骥，enjoy！


**持续更新中。**

## 讲座梗概

---

> - 第1讲：AI鸟瞰与升级指南
> - 第2讲：机器学习入门
> - 第3讲：经典神经网络
> - 第4讲：深度神经网络
> - 第5讲：卷积神经网络
> - 第6讲：视觉分类任务
> - 第7讲：视觉探测任务
> - 第8讲：实例与调参



## 第1讲：AI鸟瞰与升级指南

主要讲了项目背景及当下AI现状，新手学习路径及方法建议。

当前新手学习AI面临的问题：理工科知识不友好，数学门槛过重，解决方案是：

1. 不讲证明
2. 以能懂能用为目标，画出知识最小包络
3. 说人话，减少学术词汇，实例形象易懂

此课程面向对象，适合于对AI感兴趣的任意背景同学，极大降低新手学习入门门槛。有深入了解原理需求的读者可按以下步骤进阶：

- 学习互助小组，了解入门
- 做项目，实操领会
- 打比赛，实战进阶
- 追论文，发论文，学术前沿

**建议学习策略**

- 推荐学习平台：Coursera, github, arxiv, papers with code
- 理论是用的，不是纯学的，类似英语语言学习，要多与实践结合
- 内功：算法，外功：代码
- 找好基友，同道中人讨论前行，连滚带爬往前走
- 合理追求quick win，设置小目标控制点，感受成就感与前进
- 设置deadline，人类前进的最大动力

## 第2讲：机器学习入门

主要讲了机器学习总体框架，以对知识地图有个宏观了解。

- 大框架：收集数据、选取特征，进行标注，拟合数据，进行预测
- 小框架：数据矩阵描述，可视化与归一化，决策边界，sigmoid激活函数，损失函数评价模型，梯度下降优化，过拟合与泛化，正则化

结合案例，生动形象地讲解了机器学习常用核心概念：

- 特征、数据集：数据准备及特征提取思路
- 归一化：数据预处理，统一量纲，加快收敛
- 决策边界：进行分类的卡尺
- 激活函数：进行非线性化处理，增大模型表达能力
- 损失函数：评价输出结果好坏
- 梯度下降：回溯更新参数
- 过拟合、欠拟合和泛化：训练模型经常遇到的效果平衡

## 第3讲：经典神经网络

主要讲了前向传播和反向传播的概念理解和公式推导，神经网络的广义性（可拟合任意函数）。

此章节为深度学习的理论核心，可根据课件反复研读实验，务必理解透彻。

## 第4讲：深度神经网络

主要讲了随着神经网络深度的不断叠加，出现的问题与解决方案。

- 梯度消失、梯度爆炸
    - 解决：换激活函数、更新初始化方法
- 过拟合
    - 解决：正则化、学习率衰减
- 数据集样本少
    - 解决：数据增强，人造各种数据或者各种渠道购买更多真实数据
- 处理大数据的方法
    - 解决：mini batch和batch norm

## 第5讲：卷积神经网络

主要讲了计算机视觉中核心卷积神经网络的原理、前向传播，广泛应用于分类、探测、语义分割、实例分割、跟踪等任务。

- 分类：识别整体图片的类别
- 探测：识别区域图片的类别并框选出类别所处图片位置
- 跟踪：动态跟踪视频中某一类别的位置，并实时框选出来
- 语义分割：将整体图片分区域归类，如大地、车、天空、树
- 实例分割：在语义分割基础上，对归类进一步细分实例化，如车A、车B、树A、树B

概要讲述了在以上任务中，基于卷积神经网络的具体模型设计应用，并练习一个典型卷积神经网络。

## 第6讲：视觉分类任务

主要讲了分类任务中的IMAGENET挑战赛中涌现出的优秀模型，各种模型的核心工作是做不同姿势的卷积，走两条路：

- 提高精度
    - LeNet5，起点，CNN，tanh激活
    - AlexNet2012，深度神经网络与大数据的首次触电，用relu加深了网络，用GPU训练起了大数据
    - ZFNet2013，过渡版本，帮AlexNet调了超参，换了卷积参数
    - VGG2014，标准模块加堆叠，换7x7卷积为3x3卷积堆叠，降低了参数量（人懒机器累）
    - GoogleNet2014，inception，变得更宽，1x1卷积压缩通道数，nxn变1xn和nx1卷积核分解，超参变更多（人累机器爽）
    - ResNet2015，打破限制，超越人类。解决加深网络问题，多加一条直连的线，保证无效神经元层直通，此时卷积核参数为0
    - ResNeXt2016，ResNet Plus，融合GoogleNet和VGG更进一层
    - SENet2017，集大成者，这届后比赛停止。Squeeze和Excitation，1X1卷积提取通道的影响，单独接个全连接网络，之后再叠加到下面的卷积网络。
- 提高效率
    - 参数压缩
        - Deep Compression
            - 效果：VGG，50倍压缩参数，便于端侧运行。
            - 方法：剪枝，聚类压缩量化编码，霍夫曼编码
    - 结构优化
        - MobileNet，ShuffleNet

## 第7讲：视觉探测任务

## 第8讲：实例与调参