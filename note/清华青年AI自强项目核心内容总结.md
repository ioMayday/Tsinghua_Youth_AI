
[toc]



本文主要梳理总结学习清华大学青年AI自强项目中的核心知识内容，各位读者可以根据需要按图索骥，enjoy！


**持续更新中。**

## 讲座梗概

---

> - 第1讲：AI鸟瞰与升级指南
> - 第2讲：机器学习入门
> - 第3讲：经典神经网络
> - 第4讲：深度神经网络
> - 第5讲：卷积神经网络
> - 第6讲：视觉分类任务
> - 第7讲：视觉探测任务
> - 第8讲：实例与调参



## 第1讲：AI鸟瞰与升级指南

主要讲了项目背景及当下AI现状，新手学习路径及方法建议。

当前新手学习AI面临的问题：理工科知识不友好，数学门槛过重，解决方案是：

1. 不讲证明
2. 以能懂能用为目标，画出知识最小包络
3. 说人话，减少学术词汇，实例形象易懂

此课程面向对象，适合于对AI感兴趣的任意背景同学，极大降低新手学习入门门槛。有深入了解原理需求的读者可按以下步骤进阶：

- 学习互助小组，了解入门
- 做项目，实操领会
- 打比赛，实战进阶
- 追论文，发论文，学术前沿

## 第2讲：机器学习入门

主要讲了机器学习总体框架，以对知识地图有个宏观了解。

- 大框架：收集数据、选取特征，进行标注，拟合数据，进行预测
- 小框架：数据矩阵描述，可视化与归一化，决策边界，sigmoid激活函数，损失函数评价模型，梯度下降优化，过拟合与泛化，正则化

结合案例，生动形象地讲解了机器学习常用核心概念：

- 特征、数据集：数据准备及特征提取思路
- 归一化：数据预处理，统一量纲，加快收敛
- 决策边界：进行分类的卡尺
- 激活函数：进行非线性化处理，增大模型表达能力
- 损失函数：评价输出结果好坏
- 梯度下降：回溯更新参数
- 过拟合、欠拟合和泛化：训练模型经常遇到的效果平衡

## 第3讲：经典神经网络

主要讲了前向传播和反向传播的概念理解和公式推导，神经网络的广义性（可拟合任意函数）。

此章节为深度学习的理论核心，可根据课件反复研读实验，务必理解透彻。

## 第4讲：深度神经网络

主要讲了随着神经网络深度的不断叠加，出现的问题与解决方案。

- 梯度消失、梯度爆炸
    - 解决：换激活函数、更新初始化方法
- 过拟合
    - 解决：正则化、学习率衰减
- 数据集样本少
    - 解决：数据增强，人造各种数据或者各种渠道购买更多真实数据
- 处理大数据的方法
    - 解决：mini batch和batch norm

## 第5讲：卷积神经网络

## 第6讲：视觉分类任务

## 第7讲：视觉探测任务

## 第8讲：实例与调参